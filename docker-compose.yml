version: "3.9"

# ─────────────────────────────────────────────────────────────────────────────
# Shared network so all AI micro-services can talk to each other
# ─────────────────────────────────────────────────────────────────────────────
networks:
  ai_network:
    driver: bridge

# ─────────────────────────────────────────────────────────────────────────────
# Volumes (optional – only used if you mount weights from outside the image)
# ─────────────────────────────────────────────────────────────────────────────
volumes:
  model_weights:

services:

  # ── Liver-Tumor Detector (your model) ──────────────────────────────────────
  liver_tumor_api:
    build:
      context: .
      dockerfile: Dockerfile
    image: liver_tumor_api:latest
    container_name: liver_tumor_api
    restart: unless-stopped
    ports:
      - "8000:8000"           # host:container
    environment:
      MODEL_PATH: /app/best_model.pth
      IMG_SIZE: 224
    networks:
      - ai_network
    healthcheck:
      test: ["CMD", "python", "-c",
             "import urllib.request; urllib.request.urlopen('http://localhost:8000/health')"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 20s

  # ── API Gateway / reverse-proxy (Nginx) ────────────────────────────────────
  # Uncomment if you want a single entry-point that routes to all AI services.
  # nginx:
  #   image: nginx:1.25-alpine
  #   container_name: nginx_gateway
  #   restart: unless-stopped
  #   ports:
  #     - "80:80"
  #   volumes:
  #     - ./nginx.conf:/etc/nginx/nginx.conf:ro
  #   depends_on:
  #     - liver_tumor_api
  #   networks:
  #     - ai_network

  # ── Placeholder for a second AI model ──────────────────────────────────────
  # Duplicate this block for each additional model container.
  # model_b_api:
  #   image: model_b_api:latest
  #   container_name: model_b_api
  #   restart: unless-stopped
  #   ports:
  #     - "8001:8000"
  #   networks:
  #     - ai_network
